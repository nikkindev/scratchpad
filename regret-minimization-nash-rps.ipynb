{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using conterfactual regret minimization to find Nash equilibrium in Rock, Paper, Scissors\n",
    "Refs:  \n",
    "- http://modelai.gettysburg.edu/2013/cfr/cfr.pdf\n",
    "- https://github.com/RichardKelley/cfr/blob/master/rps.py\n",
    "\n",
    "### Algorithm\n",
    "- Rock, Paper and Scissors are encoded as 0,1,2\n",
    "- Strategies are computed from positive regret (If regret <= 0, uniform strategy)\n",
    "- Add strategy to strategy profile sum\n",
    "- Get actions for each strategy\n",
    "- Compute regrets for actions\n",
    "- Use regrets to compute new strategies and repeat...\n",
    "- Compute average strategy profile at the end\n",
    "\n",
    "Note: This execution is for a mixed strategy for the opponent so we can compute the Nash equilibruim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nash Equilibrium\n",
      "Player 1 (me):\t [0.3333, 0.3333, 0.3333] \n",
      "Player 2 (opp):\t [0.3333, 0.3333, 0.3333]\n",
      "Computed in 7.12 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def get_strategy(regret_sum):\n",
    "  strategy = np.array([i if i > 0 else 0 for i in regret_sum])  # Consider only positive regret values\n",
    "  if(sum(strategy) > 0):  strategy = np.array([i/sum(strategy) for i in strategy])  # Case check for [0,0,0]\n",
    "  else: strategy = np.array([1/3,1/3,1/3])\n",
    "  return(strategy)\n",
    "\n",
    "def get_action(strategy):\n",
    "  # Choosing action based on probability distribution\n",
    "  return(np.random.choice(np.arange(num_actions),1,p = strategy)[0])  \n",
    "  \n",
    "\n",
    "def get_utility(action):\n",
    "  # Utility is always cyclic in 0,1,-1 for RPS in that order\n",
    "  util = np.array([0.0,0.0,0.0]) \n",
    "  util[(opp_action+1)%3] = 1  \n",
    "  util[(opp_action+2)%3] = -1\n",
    "  return(util)\n",
    "\n",
    "rock, paper, scissors = 0,1,2\n",
    "num_actions = 3\n",
    "\n",
    "my_strategy_sum = np.array([0.0,0.0,0.0])\n",
    "my_regret_sum = np.array([0.0,0.0,0.0])\n",
    "\n",
    "opp_strategy_sum = np.array([0.0,0.0,0.0])\n",
    "opp_regret_sum = np.array([0.0,0.0,0.0])\n",
    "\n",
    "for i in range(100000):\n",
    "  my_strategy = get_strategy(my_regret_sum)\n",
    "  opp_strategy = get_strategy(opp_regret_sum) \n",
    "  # opp_strategy can be a fixed p-distrib array if opponent takes a pure strategy instead of mixed\n",
    "  \n",
    "  # Summing all strategies to be averaged at the end\n",
    "  my_strategy_sum += my_strategy\n",
    "  opp_strategy_sum += opp_strategy\n",
    "  # Choosing actions based on strategies\n",
    "  my_action = get_action(my_strategy)\n",
    "  opp_action = get_action(opp_strategy)\n",
    "\n",
    "  util_for_my_action = get_utility(my_action)  #Utility for choosing my action vs. all actions\n",
    "  util_for_opp_action = get_utility(opp_action)  #Utility for choosing opponent's action vs. all actions\n",
    "\n",
    "  my_regret_sum = util_for_opp_action - util_for_opp_action[my_action]\n",
    "  opp_regret_sum = util_for_my_action - util_for_my_action[opp_action]\n",
    "\n",
    "print(\"Nash Equilibrium\\nPlayer 1 (me):\\t\",[round(i/sum(my_strategy_sum),4) for i in my_strategy_sum], \"\\nPlayer 2 (opp):\\t\",[round(i/sum(opp_strategy_sum),4) for i in opp_strategy_sum])\n",
    "print(\"Computed in\",round(time.time()-start,2),\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
